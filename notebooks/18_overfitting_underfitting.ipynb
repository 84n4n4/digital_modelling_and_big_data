{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Overfitting and Underfitting",
   "id": "40a52b06afb92e72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ],
   "id": "d733d7c35ed57998",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our initial function is just a cosine wave with some noise added on top",
   "id": "b755bd23f52a4215"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "\n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * 0.1"
   ],
   "id": "2116e01c1be33a17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(X,y)\n",
    "plt.show()"
   ],
   "id": "1c21ee7c89cecbfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training a simple linear regressor on this data does not perform well.",
   "id": "cb659a01bfb471a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X[:, np.newaxis], y)\n",
    "\n",
    "X_test = np.linspace(0, 1, 100)\n",
    "y_pred = linear_regression.predict(X_test[:, np.newaxis])\n",
    "plt.plot(X_test, y_pred, label=\"Model\")\n",
    "plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "fc04eac0bf177340",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Using the polynomials trick from last jupyter notebook we can help our model to capture the function a bit better. Lets put what we did above and the ploynomial creation in a function so we can call it with different degrees.",
   "id": "d1950a984fabdf78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def linear_regression_with_polynomials_of_degree(degree):\n",
    "    polynomial_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    linear_regression = RandomForestRegressor()\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression),\n",
    "        ]\n",
    "    )\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "    \n",
    "    \n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    y_pred = pipeline.predict(X_test[:, np.newaxis])\n",
    "    plt.plot(X_test, y_pred, label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "c87b67adbcba6935",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Calling this with degree = 1  leads to the same model as above.",
   "id": "a457b2ab2dbc750"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "linear_regression_with_polynomials_of_degree(1)",
   "id": "724145753d62d6f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How about degree = 2?\n",
    "This is looking better, but we are still underfitting, meaning that our model can not grasp the complexity of the true function."
   ],
   "id": "7792ef33cec7b115"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "linear_regression_with_polynomials_of_degree(2)",
   "id": "dfd17845cc74cb68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "How about degree = 4?",
   "id": "64875df3ba548a8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "linear_regression_with_polynomials_of_degree(4)\n",
   "id": "50fd9a6030a3be5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Almost perfect, but what happens if we start to increase the number of degrees further?",
   "id": "f3df3aa74af36d64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "linear_regression_with_polynomials_of_degree(4)\n",
   "id": "6e6203d4e63431c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The output above starts having similarities with the noise in the original inputs. We are now significantly overfitting. While the model captures the original trainingset in moore and more detail, it actually is getting worse in modelling the true function.",
   "id": "c9ec0b0997111773"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(X,y)\n",
    "plt.show()"
   ],
   "id": "dbc4be1be92a7733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "73de794dfb0b7338",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
