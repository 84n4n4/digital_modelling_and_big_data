{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Science Project\n",
   "id": "aca91401c24146be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This data science project is split into tasks. Task 1 is to analyze and visualize the dataset. Task 2 is to train a machine learning model for a specific task on the dataset. Task 3 is to make a 5-10 min presentation of your results.",
   "id": "3507e4f7ea2e747e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## The dataset",
   "id": "db4146a0818521f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The provided dataset (`../../data/pv_sandia/pv_sandia_modules.csv`) contains information about different models of PV modules manufactured by sandia and an exemplary yearly energy output for each module.\n",
    "The goal: Predict the energy output mainly based on area. However, you are free (and you will probably need) to use additional features contained in the dataset aswell."
   ],
   "id": "22526db6e677b60d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "If for some reason you want to work on another dataset more related to your field of study, you can do this. However, it must be an open dataset, the task should not be easier than the provided PV dataset, it must contain at least on categorical variable, at least one numerical variable as input, and one numerical variable as output, alternatively you can also do classification tasks on some alternative dataset.\n",
    "**If you want to work on another dataset, you must contact me first (either mail or in person during next lecture).**\n",
    "A few sample sources for such data are:\n",
    "\n",
    "- tawes weather data https://data.hub.geosphere.at/group/stationsdaten\n",
    "- population styria https://www.data.gv.at/katalog/en/dataset/72fca720-16e1-11e3-8ffd-0800200c9a66\n",
    "- waste management styria https://www.data.gv.at/katalog/en/dataset/b13ebd10-3579-11e2-81c1-0800200c9a66#additional-info\n",
    "- pv plants in vienna https://www.data.gv.at/katalog/en/dataset/3393de7c-1c7d-428e-801b-cce5e7495279#additional-info\n",
    "- electrical vehicles austria https://www.data.gv.at/katalog/en/dataset/16abce7d-af65-45e5-bc13-0106c9a0f99b#resources\n",
    "- commercial air traffic in austria https://data.statistik.gv.at/web/meta.jsp?dataset=OGD_zlf_komm_ZLF_KOM_1\n",
    "- western europe electrical power consumption https://www.kaggle.com/datasets/francoisraucent/western-europe-power-consumption"
   ],
   "id": "fa7452fdea9ec2d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 1 Data analysis / visualization / preprocessing.",
   "id": "e4c569c7342054b4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What is the data? What features/values are in the dataset. (Dont worry, I also dont know what half of them mean.) However, even if we dont know half of it, we can still find useful information in the dataset.\n",
    "\n",
    "- What columns are numerical, dates, times, categorical, free text, etc.\n",
    "- Visualize the dataset to get an overview.\n",
    "- What values/columns correlate with each other and how strongly.\n",
    "- How do you check if categorical values are correlated to other features?\n",
    "- If there are correlations and connections between features, are they linear?"
   ],
   "id": "e36a418d2e7ed3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f3b8bedfa3308b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 2 ML Models",
   "id": "54fbdaeb2367daa9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Train a ML regressor to model the problem. Models offered by sklearn are probably the easiest to handle (and occur in the lectures jupyter notebooks), however, you are free to use more advanced models, as for example neural network based models (keras, pytorch) if you wish to do so. \n",
    "You have to perform a proper train test split (at least 0.2 train size). In any case, you are not bound to train only a single model, you can train multiple different models and discuss their difference in performance or combine predictions to a final verdict.\n",
    "Performance is to be measured at least in MSE (mean squared error), MAPE (mean average percentage error), and R2 (coefficient of determination). Feel free to use further performance metrics."
   ],
   "id": "c94ea07c129853e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7f3d2c5921b365f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Task 3 Presentation",
   "id": "f15c43fbe4fd9090"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Make a 5-10 min presentation of your results. Include details on your approach towards task 1 and 2, what caused you problems, which ones were you able to solve. What interesting things you found in the datasets. How your ML models fared in the end, and ideas on how one could increase the performance.",
   "id": "e604bf9e758b9039"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c85d831a04b1990a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
